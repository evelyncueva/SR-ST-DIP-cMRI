{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerrequisitos \n",
    "\n",
    "## Dependencias \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as np \n",
    "from jax import random, jit, vmap \n",
    "from inrmri.data_harvard import load_data_without_bart\n",
    "from inrmri.data_splitter import SimpleDataLoader\n",
    "from inrmri.fourier_features import FF_fraction_static_mixed_net\n",
    "from inrmri.radon_training import spacelim, spoke_loss_fourierspace_phase\n",
    "\n",
    "from inrmri.basic_nn import simple_train \n",
    "import optax \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# semillas para reproducir el entrenamiento \n",
    "\n",
    "random_seed  = 0\n",
    "\n",
    "key_split, key_B, key_init, key_train = random.split(random.PRNGKey(random_seed), 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BART Toolbox \n",
    "\n",
    "Correr el ejemplo requiere tener instalado el [BART Toolbox](https://mrirecon.github.io/bart/). Ver las instrucciones el el [`README-es`](../README-es.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtener datos y generar el conjunto de entrenamiento \n",
    "\n",
    "Los datos se obtendrán de [Replication Data for: Multi-Domain Convolutional Neural Network (MD-CNN) For Radial Reconstruction of Dynamic Cardiac MRI](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi%3A10.7910%2FDVN%2FCI3WB6&version=2.0&q=&fileAccess=&fileTag=&fileSortField=&fileSortOrder=). \n",
    "\n",
    "## Parámetros para el procesamiento de datos \n",
    "\n",
    "- `chosen_patient`:`str` en `\"P01\"`, `\"P02\"`, ..., `\"P15\"`. El código funciona con cualquiera que esté en el diccionario `HARVARD_DB_IDs` de `inrmri.data_harvard`. Es posible añadir pacientes extras añadiendo nuevas keys al diccionario. El _id_ pedido es único a cada paciente y es parte del URL de descarga como un código de 6 valores (letras o números) que está después del _id_ del repositorio (`CI3WB6`). Para [el paciente `P100`](https://dataverse.harvard.edu/file.xhtml?persistentId=doi:10.7910/DVN/CI3WB6/HR66QD&version=2.0) por ejemplo, su _id_ es `HR66QD`.\n",
    "\n",
    "- `sub_spokes_per_frame`:`int`. Relacionado con el factor de aceleración que se desea. Los datos disponible son (casi) totalmente muestreados (usualmente 196 _spokes_ disponibles para reconstruir una imagen de 208x208, lo que da un factor de aceleración muy bajo de $208/196 \\approx 1.06$). Pero nos interesa hacer reconstrucciones submuestreadas, es decir, con muchas menos _spokes_ por frame. Usar 16 spokes por frame (`sub_spokes_per_frame=16`) es una cantidad razonable. Usar más debería dar mejores reconstrucciones (pero considerar que el tamaño del _training set_ es directamente proporcional a la cantidad de _spokes_ por frame, por lo que habría que aumentar el número de iteraciones para mantener el mismo número de _epochs_). Yo suelo usar 8, y también es posible usar menos, pero en general deja de tener sentido físico usar factores de aceleración tan grandes (usando menos de 8 spokes por frame, el total de spokes que se adquirirían prospectivamente no alcanza para un ciclo cardíaco completo).\n",
    "\n",
    "- `CSMAP_FOLDER`: Directorio donde están almacenados los mapas de sensibilidad, con nombres de la forma `csmap-P01.npy` (`csmap-` + `'chosen_patient'` + `.npy`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_patient = \"P07\"\n",
    "sub_spokes_per_frame = 12\n",
    "CSMAP_FOLDER = '/home/tabita/ACIP-MRI/ACIP-MRI/data_coils/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos \n",
    "\n",
    "A partir del diccionario de configuración, se utiliza la función `load_data` para cargar todo lo necesario. La primera vez que se usa con un paciente descarga el dataset y lo guarda en una carpeta `harvardDB/` que debe haber sido creada previamente. También debe existir `data_bart/`, donde se guardarán las archivos generados por BART: \n",
    "\n",
    "- `X_full, Y_full`: conjunto de entrenamiento para la red. Al cargar los datos con `hermitic_fill=True` y `relaxed_pad_removal=False`, la dimensión de _read out_ (el largo de las _spokes_) es de 414. Cada spoke se trata como 1 dato (es decir `batch_size=2` corresponde a 2 spokes). El total de datos entonces es `sub_spokes_per_frame * total_frames`, donde `total_frames` es la cantidad total de frames en que están agrupados los datos. `X_full:array[float]` tiene la información de todas las _spokes_ resultantes luego del submuestreo (la ubicación de las frecuencias adquiridas en el k-space específicamente), además del _frame_ al que están asociadas. `Y_full:array[complex]` tiene las mediciones de cada _spoke_ para cada una de las bobinas.\n",
    "  - `X_full.shape = (sub_spokes_per_frame * total_frames, 414 + 1, 2)`. El 1 del `414 + 1` es una forma fea de añadir el tiempo de la adquisición a los datos, y el 2 es porque las adquisiciones son 2D en el k-space ($k_x, k_y$).\n",
    "  - `Y_full.shape = (sub_spokes_per_frame * total_frames, n_coils, 414, 1)`. `n_coils` es el número de bobinas con que se adquirieron los datos. El 1 es porque facilita ajustar los datos con la dimensión de salida de la red.\n",
    "- `csmap:array[complex]`: mapas de sensibilidad estimados con BART a partir de los datos totalmente muestreados. `csmap.shape = (n_coils, 414, 414)` (el largo de la _spoke_ determina el tamaño de la imagen reconstruida).\n",
    "- `im:array[complex]`: una reconstrucción de referencia (un vídeo) obtenida a partir de la adquisición totalmente muestreada y GRASP con parámetros $\\lambda = 1\\times10^{-3}, \\mathcal{L} = 5\\times 10^{-4}$ y 100 iteraciones. `im.shape = (414,414,total_frames)`. \n",
    "- `hollow_mask:array[float]`: usualmente los mapas de sensibilidad tienen zonas donde todas las bobinas tienen sensibilidad 0. Esto impide que red sea capaz de estimar una reconstrucción en esas zonas, porque no tienen ninguna importancia en la función de pérdida. Esto en general no importa, ya que esas zonas suelen estar fuera del cuerpo, así que es razonable que la estimación allí sea 0. En la práctica, se permite que la red prediga cualquier cosa en esas zonas y luego se usa la máscara para cubrirlas con 0s. `hollow_mask.shape = (414,414)` y *marca las zonas en las que no se pueden reconstruir*, es decir, vale 1 donde no se puede optimizar la red (la zona que se va a enmascarar posteriormente) y 0 donde sí se puede optimizar.\n",
    "\n",
    "\n",
    "La función `get_splitted_dataset` me permite dejar algunas _spokes_ como conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full, Y_full, csmap, im, hollow_mask = load_data_without_bart(chosen_patient, sub_spokes_per_frame, CSMAP_FOLDER)\n",
    "\n",
    "loader = SimpleDataLoader(X_full, Y_full)\n",
    "\n",
    "training_fraction = 0.7 \n",
    "\n",
    "X_train, Y_train, X_val, Y_val = loader.get_splitted_dataset(key_split, training_fraction)\n",
    "\n",
    "trainset = (X_train, Y_train)\n",
    "valset = (X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar la reconstrucción de referencia, los mapas de sensibilidad y la máscara\n",
    "\n",
    "chosen_csmap = 12 \n",
    "chosen_frame = 15 \n",
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "# TODO: hacer las recos \n",
    "# plt.subplot(131)\n",
    "# plt.imshow(np.abs(im[...,chosen_frame]), cmap='bone')\n",
    "# plt.title(f\"Reconstrucción completamente, \\nmuestreada en el {chosen_frame}-ésimo frame\")\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(np.abs(csmap[chosen_csmap]))\n",
    "plt.title(f\"{chosen_csmap}-ésimo mapa de sensibilidad\")\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(hollow_mask, cmap='Reds')\n",
    "plt.title(f\"Zonas donde la reconstrucción \\n de la red está indeterminada\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar la red \n",
    "\n",
    "Por simplicidad voy a elegir la red tipo `FF_fraction_static_mixed_net`, que es la que ha dado mejores resultados. Esta red usa un vector de Fourier Features de tipo STiFF, descrito [en este paper](https://arxiv.org/pdf/2307.14363.pdf), que está dado por\n",
    "\n",
    "$$\n",
    "\\gamma(\\mathbf{x}, t; \\beta) =\n",
    "\\begin{bmatrix}\n",
    "\\cos(2\\pi B_{\\text{s}}\\mathbf{x}) \\\\\n",
    "\\sin(2\\pi B_{\\text{s}}\\mathbf{x}) \\\\\n",
    "\\cos(2\\pi B_{\\text{d}}\\mathbf{x})\\cos(2 \\pi t) \\\\\n",
    "\\cos(2\\pi B_{\\text{d}}\\mathbf{x})\\sin(2 \\pi t) \\\\ \n",
    "\\sin(2\\pi B_{\\text{d}}\\mathbf{x})\\cos(2 \\pi t) \\\\\n",
    "\\sin(2\\pi B_{\\text{d}}\\mathbf{x})\\sin(2 \\pi t)\n",
    "\\end{bmatrix} \\in \\mathbb{R}^{2M_{\\text{s}} + 4M_{\\text{d}}}\n",
    "$$\n",
    "\n",
    "Cada componente de $B_s \\in \\mathbb{R}^{M_s \\times 2}$ y $B_d \\in  \\mathbb{R}^{M_d \\times 2}$ viene de una normal $\\mathcal{N}(0,\\sigma)$. El largo del vector STiFF es $L = 2M_s + 4M_d$. Se define $p_s:= \\frac{2M_s}{L}$ como la fracción de componentes del vector STiFF que no dependen del tiempo.\n",
    "\n",
    "\n",
    "- `sigma:float`: parámetro $\\sigma$, relacionado con las frecuencias que la red aprende más rápidamente. Para este dataset, usualmente valores de $\\sigma \\in [3, 12]$ dan buenos resultados.\n",
    "- `desired_ffvector_len:int`: Aproximadamente $L$, el largo del vector de Fourier Features. En general, mientras más grande, más robusto se hacen los resultados al valor de `sigma`, pero también requiere más memoria.\n",
    "- `static_fraction:float`: parámetro $p_s \\in [0,1]$ asociado a la regularización temporal: mientras más cercano a 1, mayor regularización. Depende del submuestreo, mientras más submuestreo (menos datos, menor `sub_spokes_per_frame`) se necesita más regularización. Para `sub_spokes_per_frame=8`, `static_fraction` entre 0.65 y 0.8 funciona bien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FFnet = FF_fraction_static_mixed_net(static_fraction=0.8, #\n",
    "                                     desired_ffvector_len=1000,\n",
    "                                     sigma=7.5,\n",
    "                                     imshape=(414,414,25), #usualmente sería im.shape, \n",
    "                                     complex_output=True, # las imágenes de MRI son complejas\n",
    "                                     key=key_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir la función de pérdida "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spclim = spacelim(X_train[:,1:,:]) # esto era para definir el dominio (en el kspace o en imagen, ya no me acuerdo)\n",
    "\n",
    "short_spoke_loss = lambda params, train_X_sample, train_Y_sample: spoke_loss_fourierspace_phase(params, train_X_sample, train_Y_sample, spclim, 1., csmap, FFnet, 'ramp')\n",
    "radon_fourier_loss_fourierspace_phase = jit(lambda params, train_X, train_Y: np.mean(vmap(short_spoke_loss, in_axes = (None, 0, 0))(params, train_X, train_Y)))\n",
    "loss = lambda params, train_X, train_Y: radon_fourier_loss_fourierspace_phase(params, train_X, train_Y) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar la red "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_layers = [512, 512, 512]\n",
    "\n",
    "nIter = 1000 # 1k para probar, pero usualmente se necesita 10k, y sigue mejorando un poco hasta 20k\n",
    "batch_size = 1 # lo maximo para una gpu de 10gb con esta configuracion de inner_layer y frac_static_mixed_params[1]\n",
    "learning_rate = 1e-3 # TODO: ver cual usé \n",
    "\n",
    "params = FFnet.init_params(inner_layers, key = key_init)\n",
    "\n",
    "optimizer = optax.adam(learning_rate)\n",
    "\n",
    "results = simple_train(loss, *trainset, params,  optimizer, key_train, batch_size = batch_size, nIter = nIter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisar resultados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results['iterations'], results['train_loss'])\n",
    "plt.yscale('log')\n",
    "plt.title('Evolución de la _loss_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 8 \n",
    "\n",
    "from jax.lax import map as laxmap \n",
    "\n",
    "def post_processing(im): # im.shape (px,py,nframes)\n",
    "    is_inside = is_inside_of_radial_lim(FFnet._gridX, 1.)\n",
    "    masks = (1 - hollow_mask) * is_inside\n",
    "    return im * masks[:,:,None]\n",
    "    \n",
    "\n",
    "def vmap_image_pred(params):\n",
    "    return vmap(FFnet.image_prediction_at_timeframe, in_axes=(None, 0), out_axes=-1)(params, FFnet._gridt) \n",
    "\n",
    "def laxmap_image_pred(params):\n",
    "    reco = laxmap(lambda t: FFnet.image_prediction_at_timeframe(params, t), FFnet._gridt) \n",
    "    \n",
    "    return np.moveaxis(reco, 0,-1)\n",
    "\n",
    "from inrmri.utils import is_inside_of_radial_lim\n",
    "\n",
    "# is_inside = is_inside_of_radial_lim()\n",
    "\n",
    "fullreco = post_processing(laxmap_image_pred(results['last_param'])) # shape (414,414,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullreco.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(121)\n",
    "# plt.imshow(np.abs(im[...,frame]), cmap='bone') # TODO \n",
    "plt.title(f\"Reconstrucción completamente, \\nmuestreada en el {frame}-ésimo frame\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.abs(fullreco[...,frame]), cmap='bone')\n",
    "plt.title(f\"Reconstrucción Neural Fields\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.abs(fullreco)[:,fullreco.shape[1]//2,:].transpose(), cmap='bone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcular métricas \n",
    "\n",
    "## Métricas disponibles \n",
    "\n",
    "El diccionario `METRIC_FUNCTIONS` de `inrmri.metrics` tiene varias métricas implementadas. \n",
    "metrics_values \n",
    "- `'ssim_3D'`: a pesar del nombre, esta es la SSIM estándar, calculada sobre la imagen completa (como suelo trabajar con vídeos, mis imágenes son 3D y la llamada así para distinguirla de la siguiente)\n",
    "- `'mean_ssim_2D'`: calcula la SSIM frame por frame y la promedia. Asume que las imagenes tienen shape `(px, py, total_frames)`.\n",
    "- `'psnr'`\n",
    "- `'ism_fsim'`, `'ism_issm'`, `'ism_psnr'`, `'ism_rmse'`: están directamente extraídas del paquete [https://pypi.org/project/image-similarity-measures/](https://pypi.org/project/image-similarity-measures/). No sé por qué `'ism_fsim'` no está funcionando con imágenes 2D.\n",
    "\n",
    "## Preprocesamiento \n",
    "\n",
    "Suelo calcular las métricas en torno al corazón. La variable `PATIENTS_CROPS` de `inrmri.data_harvard` tiene calculadas las zonas adecuadas para varios pacientes. El preprocesamiento, que suele incluir corte, normalización y cálculo del valor absoluto, se realiza con `BeforeNormalizer` o `BeforeLinRegNormalizer`. El primero normaliza por la máxima intensidad del píxel en la zona cortada, el segundo escala la imagen por un factor adecuado de forma que maximize el PSNR, por lo que requiere la imagen de referencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inrmri.metrics import METRIC_FUNCTIONS \n",
    "\n",
    "print(\"The available metrics are: \" + str(list(METRIC_FUNCTIONS.keys())))\n",
    "\n",
    "from inrmri.image_processor import BeforeLinRegNormalizer, BeforeNormalizer \n",
    "from inrmri.data_harvard import PATIENTS_CROPS \n",
    "\n",
    "crop_ns = PATIENTS_CROPS[chosen_patient]\n",
    "improc = BeforeLinRegNormalizer(im[...,frame], crop_ns)\n",
    "# improc = BeforeNormalizer(crop_ns)\n",
    "\n",
    "chosen_metrics = ['ssim_3D', 'psnr'] # no todas funcionan en 2D \n",
    "\n",
    "processed_reco = improc.process(fullreco)\n",
    "processed_ref = improc.process(im)\n",
    "\n",
    "metrics_values = {\n",
    "    metric_name: METRIC_FUNCTIONS[metric_name](processed_ref, processed_reco) for metric_name in chosen_metrics\n",
    "}\n",
    "\n",
    "metrics_values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(processed_ref, cmap='bone')\n",
    "plt.title(f\"Reconstrucción completamente, \\nmuestreada en el {frame}-ésimo frame \\n en la zona del corazón\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(processed_reco, cmap='bone')\n",
    "metrics_str = \" \".join([f\"\\n{metric_name} {metric_val:.2f}\" for metric_name, metric_val in metrics_values.items()])\n",
    "plt.title(f\"Reconstrucción Neural Fields\" + metrics_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
