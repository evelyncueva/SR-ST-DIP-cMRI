{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerrequisitos \n",
    "\n",
    "## Dependencias \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as np \n",
    "from jax import random \n",
    "\n",
    "from inrmri.data_harvard import load_data\n",
    "from inrmri.data_splitter import SimpleDataLoader\n",
    "from inrmri.fourier_features import FF_fraction_static_mixed_net\n",
    "from inrmri.radon_training import spacelim, spoke_loss_fourierspace_phase\n",
    "from inrmri.loggers import LocalLogger \n",
    "\n",
    "from inrmri.basic_nn import simple_train \n",
    "import optax \n",
    "\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BART Toolbox \n",
    "\n",
    "Correr el ejemplo requiere tener instalado el [BART Toolbox](https://mrirecon.github.io/bart/). Ver las instrucciones el el [`README-es`](../README-es.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtener datos y generar el conjunto de entrenamiento \n",
    "\n",
    "Los datos se obtendr√°n de [Replication Data for: Multi-Domain Convolutional Neural Network (MD-CNN) For Radial Reconstruction of Dynamic Cardiac MRI](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi%3A10.7910%2FDVN%2FCI3WB6&version=2.0&q=&fileAccess=&fileTag=&fileSortField=&fileSortOrder=). \n",
    "\n",
    "## Par√°metros para el procesamiento de datos \n",
    "\n",
    "- `chosen_patient`:`str` en `\"P01\"`, `\"P02\"`, ..., `\"P15\"`. El c√≥digo funciona con cualquiera que est√© en el diccionario `HARVARD_DB_IDs` de `inrmri.data_harvard`. Es posible a√±adir pacientes extras a√±adiendo nuevas keys al diccionario. El _id_ pedido es √∫nico a cada paciente y es parte del URL de descarga como un c√≥digo de 6 valores (letras o n√∫meros) que est√° despu√©s del _id_ del repositorio (`CI3WB6`). Para [el paciente `P100`](https://dataverse.harvard.edu/file.xhtml?persistentId=doi:10.7910/DVN/CI3WB6/HR66QD&version=2.0) por ejemplo, su _id_ es `HR66QD`.\n",
    "- `hermitic_fill`:`bool` Este dataset fue adquirido con [_partial echo_](https://www.mr-tip.com/serv1.php?type=db1&dbs=Partial%20Echo) (ver imagen), es decir, los datos radiales no son sim√©tricos en el k-space con respecto al centro. Usar `hermitic_fill = True` completa los datos faltantes.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"partial-echo.png\" alt=\"Partial echo\" width=\"300\"/>\n",
    "</p>\n",
    "\n",
    "\n",
    "- `relaxed_pad_removal`:`bool`. El oversampling usual de un data set radial corresponde a adquirir spokes de tama√±o 400. Las de este dataset son de 800; todo los datos adicionales son 0. El preprocesamiento elimina este padding sim√©tricamente (a ambos lados de la _spoke_, de forma que el centro no queda desalineado. Eso es muy importante para que la transformada de Fourier funcione despu√©s) de dos formas posibles: el modo _relaxed_ (`relaxed_pad_removal=True`) elimina todos los 0s que puede de forma sim√©trica sin eliminar ning√∫n dato no nulo. El modo _agresive_ (`relaxed_pad_removal=False`) elimina sim√©tricamente hasta que no quedan 0s en los extremos de la spoke. La diferencia es m√≠nima en el caso en que `hermitic_fill=True`. Cuando `hermitic_fill=False`, el _partial echo_ de los datos hace que la diferencia entre ambos modos sea m√°s significativa. En este caso el k-space generado con _relaxed_ permite tener una imagen de mayor resoluci√≥n pero que puede ser inconsistente (ciertas spokes dir√°n que euna zona tiene frecuencias 0, mientras que las spokes con el √°ngulo contrario dir√°n que s√≠ hay valores en usa zona). Pero, si recuerdo bien (üòÇ), las reconstrucciones que se obten√≠an eran razonables igualmente. El modo _agressive_ pierde bastante resoluci√≥n porque elimina todos los datos \"no sim√©tricos\". \n",
    "\n",
    "> üìå \n",
    "> Se recomienda usar `hermitic_fill=True` y `relaxed_pad_removal=False`.\n",
    "\n",
    "- `sub_spokes_per_frame`:`int`. Relacionado con el factor de aceleraci√≥n que se desea. Los datos disponible son (casi) totalmente muestreados (usualmente 196 _spokes_ disponibles para reconstruir una imagen de 208x208, lo que da un factor de aceleraci√≥n muy bajo de $208/196 \\approx 1.06$). Pero nos interesa hacer reconstrucciones submuestreadas, es decir, con muchas menos _spokes_ por frame. Usar 16 spokes por frame (`sub_spokes_per_frame=16`) es una cantidad razonable. Usar m√°s deber√≠a dar mejores reconstrucciones (pero considerar que el tama√±o del _training set_ es directamente proporcional a la cantidad de _spokes_ por frame, por lo que habr√≠a que aumentar el n√∫mero de iteraciones para mantener el mismo n√∫mero de _epochs_). Yo suelo usar 8, y tambi√©n es posible usar menos, pero en general deja de tener sentido f√≠sico usar factores de aceleraci√≥n tan grandes (usando menos de 8 spokes por frame, el total de spokes que se adquirir√≠an prospectivamente no alcanza para un ciclo card√≠aco completo).\n",
    "- `tiny_number`:`int`. El dataset fue adquirido con espaciado uniforme (con √°ngulo de $2\\pi/196$ entre una _spoke_ y la siguiente, de forma que al adquirir las 196 se d√© una vuelta completa al k-space). Una forma m√°s eficiente es usar submuestreo con [_golden angle_ o _tiny golden angle_](https://onlinelibrary.wiley.com/doi/epdf/10.1002/jmri.28187). Las spokes que se toman del dataset intentan replicar este tipo de submuestreo. El par√°metro `tiny_number` permite usar el _tiny golden angle_. \n",
    "\n",
    "> üìå \n",
    "> Se recomienda usar `tiny_number=1` (correspondiente al _golden angle_) o el mismo valor usado en `sub_spokes_per_frame`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed  = 0\n",
    "\n",
    "key_split, key_B, key_init, key_train = random.split(random.PRNGKey(random_seed), 4)\n",
    "\n",
    "config_data = {\n",
    "    'chosen_patient'        : \"P02\", \n",
    "    'hermitic_fill'         : True, \n",
    "    'relaxed_pad_removal'   : False,\n",
    "    'sub_spokes_per_frame'  : 12, \n",
    "    'tiny_number'           : 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos \n",
    "\n",
    "A partir del diccionario de configuraci√≥n, se utiliza la funci√≥n `load_data` para cargar todo lo necesario. La primera vez que se usa con un paciente descarga el dataset y lo guarda en una carpeta `harvardDB/` que debe haber sido creada previamente. Tambi√©n debe existir `data_bart/`, donde se guardar√°n las archivos generados por BART: \n",
    "\n",
    "- `X_full, Y_full`: conjunto de entrenamiento para la red. Al cargar los datos con `hermitic_fill=True` y `relaxed_pad_removal=False`, la dimensi√≥n de _read out_ (el largo de las _spokes_) es de 414. Cada spoke se trata como 1 dato (es decir `batch_size=2` corresponde a 2 spokes). El total de datos entonces es `sub_spokes_per_frame * total_frames`, donde `total_frames` es la cantidad total de frames en que est√°n agrupados los datos. `X_full:array[float]` tiene la informaci√≥n de todas las _spokes_ resultantes luego del submuestreo (la ubicaci√≥n de las frecuencias adquiridas en el k-space espec√≠ficamente), adem√°s del _frame_ al que est√°n asociadas. `Y_full:array[complex]` tiene las mediciones de cada _spoke_ para cada una de las bobinas.\n",
    "  - `X_full.shape = (sub_spokes_per_frame * total_frames, 414 + 1, 2)`. El 1 del `414 + 1` es una forma fea de a√±adir el tiempo de la adquisici√≥n a los datos, y el 2 es porque las adquisiciones son 2D en el k-space ($k_x, k_y$).\n",
    "  - `Y_full.shape = (sub_spokes_per_frame * total_frames, n_coils, 414, 1)`. `n_coils` es el n√∫mero de bobinas con que se adquirieron los datos. El 1 es porque facilita ajustar los datos con la dimensi√≥n de salida de la red.\n",
    "- `csmap:array[complex]`: mapas de sensibilidad estimados con BART a partir de los datos totalmente muestreados. `csmap.shape = (n_coils, 414, 414)` (el largo de la _spoke_ determina el tama√±o de la imagen reconstruida).\n",
    "- `im:array[complex]`: una reconstrucci√≥n de referencia (un v√≠deo) obtenida a partir de la adquisici√≥n totalmente muestreada y GRASP con par√°metros $\\lambda = 1\\times10^{-3}, \\mathcal{L} = 5\\times 10^{-4}$ y 100 iteraciones. `im.shape = (414,414,total_frames)`. \n",
    "- `hollow_mask:array[float]`: usualmente los mapas de sensibilidad tienen zonas donde todas las bobinas tienen sensibilidad 0. Esto impide que red sea capaz de estimar una reconstrucci√≥n en esas zonas, porque no tienen ninguna importancia en la funci√≥n de p√©rdida. Esto en general no importa, ya que esas zonas suelen estar fuera del cuerpo, as√≠ que es razonable que la estimaci√≥n all√≠ sea 0. En la pr√°ctica, se permite que la red prediga cualquier cosa en esas zonas y luego se usa la m√°scara para cubrirlas con 0s. `hollow_mask.shape = (414,414)` y *marca las zonas en las que no se pueden reconstruir*, es decir, vale 1 donde no se puede optimizar la red (la zona que se va a enmascarar posteriormente) y 0 donde s√≠ se puede optimizar.\n",
    "\n",
    "\n",
    "La funci√≥n `get_splitted_dataset` me permite dejar algunas _spokes_ como conjunto de validaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full, Y_full, csmap, im, hollow_mask = load_data(config_data)\n",
    "\n",
    "loader = SimpleDataLoader(X_full, Y_full)\n",
    "\n",
    "training_fraction = 0.7 \n",
    "\n",
    "X_train, Y_train, X_val, Y_val = loader.get_splitted_dataset(key_split, training_fraction)\n",
    "\n",
    "trainset = (X_train, Y_train)\n",
    "valset = (X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar la reconstrucci√≥n de referencia, los mapas de sensibilidad y la m√°scara\n",
    "\n",
    "chosen_csmap = 12 \n",
    "chosen_frame = 15 \n",
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.imshow(np.abs(im[...,chosen_frame]), cmap='bone')\n",
    "plt.title(f\"Reconstrucci√≥n completamente, \\nmuestreada en el {chosen_frame}-√©simo frame\")\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(np.abs(csmap[chosen_csmap]))\n",
    "plt.title(f\"{chosen_csmap}-√©simo mapa de sensibilidad\")\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(hollow_mask, cmap='Grays')\n",
    "plt.title(f\"Zonas donde la reconstrucci√≥n \\n de la red est√° indeterminada\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar la red \n",
    "\n",
    "Por simplicidad voy a elegir la red tipo `FF_fraction_static_mixed_net`, que es la que ha dado mejores resultados. Sin embargo, la funci√≥n `add_FFgroup_to_parser` permite hacer _parsing_ autom√°tico de la red a usar con un `ArgumentParser`, lo que es especialmente √∫til para elegirla f√°cilmente en scripts.\n",
    "\n",
    "- `sigma:float`: par√°metro de Fourier Features, relacionado con las frecuencias que la red aprende m√°s r√°pidamente. Para este dataset, usualmente valores de $\\sigma \\in [3, 12]$ dan buenos resultados.\n",
    "- `radon_seed:int`: semilla aleatoria (_random seed_) para tener aleatoriedad reproducible\n",
    "- `frac_static_mixed:(float,int)`: El primer valor $p_s \\in [0,1]$ est√° asociado a la regularizaci√≥n temporal: mientras m√°s cercano a 1, mayor regularizaci√≥n. El segundo valor $L$ es el largo del vector de Fourier Features. En general, mientras m√°s grande, m√°s robusto se hacen los resultados al valor de `sigma`, pero tambi√©n requiere m√°s memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma  =  7.5\n",
    "\n",
    "frac_static_mixed_params = (0.8, 1000) \n",
    "\n",
    "FFnet = FF_fraction_static_mixed_net(*frac_static_mixed_params, sigma, im, key_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir la funci√≥n de p√©rdida \n",
    "\n",
    "- `freq_filter`:`str` en `'ramp'`, `'cosine'`, `'shepp-logan'`. Se encontr√≥ que ponderar con un mayor peso las altas frecuencias en la funci√≥n de p√©rdida aceleraba la convergencia de la red. Sin embargo, [es usual que la transformada de Radon aplique una _filtered backprojection_](https://scikit-image.org/docs/stable/auto_examples/transform/plot_radon_transform.html#reconstruction-with-the-filtered-back-projection-fbp), para eliminar el ruido producido por las altas frecuencias (ver imagen de varios posibles filtros). En nuestro trabajo consideramos el peso $(1 + |k|)$ en la funci√≥n de p√©rdida, que llamamos modo `'ramp'` (notar que no es igual al de la figura). Tambi√©n se han probado `'cosine'` y `'shepp-logan'` sin diferencias significativas (hasta unas 10k), por lo que se recomienda el uso de `'ramp'`.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"high-freq-filters.png\" alt=\"High frequency filters\" width=\"500\"/>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spclim = spacelim(X_train[:,1:,:]) # esto era para definir el dominio (en el kspace o en imagen, ya no me acuerdo)\n",
    "\n",
    "# nframes = im.shape[2]\n",
    "\n",
    "from jax import jit, vmap \n",
    "\n",
    "freq_filter = 'ramp'\n",
    "\n",
    "short_spoke_loss = lambda params, train_X_sample, train_Y_sample: spoke_loss_fourierspace_phase(params, train_X_sample, train_Y_sample, spclim, 1., csmap, FFnet, freq_filter)\n",
    "radon_fourier_loss_fourierspace_phase = jit(lambda params, train_X, train_Y: np.mean(vmap(short_spoke_loss, in_axes = (None, 0, 0))(params, train_X, train_Y)))\n",
    "loss = lambda params, train_X, train_Y: radon_fourier_loss_fourierspace_phase(params, train_X, train_Y) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar la red "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = './results'\n",
    "\n",
    "inner_layers = [512, 512, 512]\n",
    "\n",
    "nIter = 1000 # 1k para probar, pero usualmente se necesita 10k, y sigue mejorando un poco hasta 20k\n",
    "batch_size = 1 # lo maximo para una gpu de 10gb con esta configuracion de inner_layer y frac_static_mixed_params[1]\n",
    "learning_rate = 1e-3 # TODO: ver cual us√© \n",
    "\n",
    "params = FFnet.init_params(inner_layers, key = key_init)\n",
    "\n",
    "# args_dic['nframes'] = nframes\n",
    "# args_dic['layers'] = inner_layers\n",
    "# args_dic['ff-type'] = FFnet.ff_type()\n",
    "\n",
    "# logger = LocalLogger(folder)\n",
    "\n",
    "# config = {}\n",
    "\n",
    "# logger_init_params = {\n",
    "#     \"project\" : \"invivo-jupyter-nb\",\n",
    "#     \"group\"   : \"\",\n",
    "#     \"config\"  : \n",
    "# }\n",
    "\n",
    "optimizer = optax.adam(learning_rate)\n",
    "\n",
    "results = simple_train(loss, *trainset, params,  optimizer, key_train, batch_size = batch_size, nIter = nIter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisar resultados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results['train_loss'])\n",
    "plt.yscale('log')\n",
    "plt.title('Evoluci√≥n de la _loss_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 8 \n",
    "\n",
    "# @jit\n",
    "# def image_pred(params, frame):\n",
    "    # return np.abs(FFnet.image_prediction_at_timeframe(params, FFnet._gridt[frame]) * (1 - hollow_mask) * is_inside) * is_inside\n",
    "\n",
    "reco = FFnet.image_prediction_at_timeframe(results['last_param'], FFnet._gridt[frame]) # shape (414,414)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(np.abs(im[...,frame]), cmap='bone')\n",
    "plt.title(f\"Reconstrucci√≥n completamente, \\nmuestreada en el {frame}-√©simo frame\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.abs(reco), cmap='bone')\n",
    "plt.title(f\"Reconstrucci√≥n Neural Fields\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcular m√©tricas \n",
    "\n",
    "## M√©tricas disponibles \n",
    "\n",
    "El diccionario `METRIC_FUNCTIONS` de `inrmri.metrics` tiene varias m√©tricas implementadas. \n",
    "metrics_values \n",
    "- `'ssim_3D'`: a pesar del nombre, esta es la SSIM est√°ndar, calculada sobre la imagen completa (como suelo trabajar con v√≠deos, mis im√°genes son 3D y la llamada as√≠ para distinguirla de la siguiente)\n",
    "- `'mean_ssim_2D'`: calcula la SSIM frame por frame y la promedia. Asume que las imagenes tienen shape `(px, py, total_frames)`.\n",
    "- `'psnr'`\n",
    "- `'ism_fsim'`, `'ism_issm'`, `'ism_psnr'`, `'ism_rmse'`: est√°n directamente extra√≠das del paquete [https://pypi.org/project/image-similarity-measures/](https://pypi.org/project/image-similarity-measures/). No s√© por qu√© `'ism_fsim'` no est√° funcionando con im√°genes 2D.\n",
    "\n",
    "## Preprocesamiento \n",
    "\n",
    "Suelo calcular las m√©tricas en torno al coraz√≥n. La variable `PATIENTS_CROPS` de `inrmri.data_harvard` tiene calculadas las zonas adecuadas para varios pacientes. El preprocesamiento, que suele incluir corte, normalizaci√≥n y c√°lculo del valor absoluto, se realiza con `BeforeNormalizer` o `BeforeLinRegNormalizer`. El primero normaliza por la m√°xima intensidad del p√≠xel en la zona cortada, el segundo escala la imagen por un factor adecuado de forma que maximize el PSNR, por lo que requiere la imagen de referencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inrmri.metrics import METRIC_FUNCTIONS \n",
    "\n",
    "print(\"The available metrics are: \" + str(list(METRIC_FUNCTIONS.keys())))\n",
    "\n",
    "from inrmri.image_processor import BeforeLinRegNormalizer, BeforeNormalizer \n",
    "from inrmri.data_harvard import PATIENTS_CROPS \n",
    "\n",
    "crop_ns = PATIENTS_CROPS[config_data['chosen_patient']]\n",
    "improc = BeforeLinRegNormalizer(im[...,frame], crop_ns)\n",
    "# improc = BeforeNormalizer(crop_ns)\n",
    "\n",
    "chosen_metrics = ['ssim_3D', 'psnr'] # no todas funcionan en 2D \n",
    "\n",
    "processed_reco = improc.process(reco)\n",
    "processed_ref = improc.process(im[...,frame])\n",
    "\n",
    "metrics_values = {\n",
    "    metric_name: METRIC_FUNCTIONS[metric_name](processed_ref, processed_reco) for metric_name in chosen_metrics\n",
    "}\n",
    "\n",
    "metrics_values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(processed_ref, cmap='bone')\n",
    "plt.title(f\"Reconstrucci√≥n completamente, \\nmuestreada en el {frame}-√©simo frame \\n en la zona del coraz√≥n\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(processed_reco, cmap='bone')\n",
    "metrics_str = \" \".join([f\"\\n{metric_name} {metric_val:.2f}\" for metric_name, metric_val in metrics_values.items()])\n",
    "plt.title(f\"Reconstrucci√≥n Neural Fields\" + metrics_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
